{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e93764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29084aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"Practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f60ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= spark.read.csv('test1_3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc3ebaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|   A|  20|         2| 30000|\n",
      "|   B|  32|         1| 20000|\n",
      "|   C|  25|         3| 10000|\n",
      "|   D|  40|         5| 32000|\n",
      "|   E|  30|         1| 14000|\n",
      "|   F|  14|         3| 30000|\n",
      "|   G|null|      null| 50000|\n",
      "|null|  24|        10| 38000|\n",
      "|null|  56|      null|  null|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42af89f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  20|         2| 30000|\n",
      "|  32|         1| 20000|\n",
      "|  25|         3| 10000|\n",
      "|  40|         5| 32000|\n",
      "|  30|         1| 14000|\n",
      "|  14|         3| 30000|\n",
      "|null|      null| 50000|\n",
      "|  24|        10| 38000|\n",
      "|  56|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 열 삭제\n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3634d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|   A|  20|         2| 30000|\n",
      "|   B|  32|         1| 20000|\n",
      "|   C|  25|         3| 10000|\n",
      "|   D|  40|         5| 32000|\n",
      "|   E|  30|         1| 14000|\n",
      "|   F|  14|         3| 30000|\n",
      "|   G|null|      null| 50000|\n",
      "|null|  24|        10| 38000|\n",
      "|null|  56|      null|  null|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ca7cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|   A| 20|         2| 30000|\n",
      "|   B| 32|         1| 20000|\n",
      "|   C| 25|         3| 10000|\n",
      "|   D| 40|         5| 32000|\n",
      "|   E| 30|         1| 14000|\n",
      "|   F| 14|         3| 30000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#null 값있는 행 모두 삭제\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb4600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|   A|  20|         2| 30000|\n",
      "|   B|  32|         1| 20000|\n",
      "|   C|  25|         3| 10000|\n",
      "|   D|  40|         5| 32000|\n",
      "|   E|  30|         1| 14000|\n",
      "|   F|  14|         3| 30000|\n",
      "|   G|null|      null| 50000|\n",
      "|null|  24|        10| 38000|\n",
      "|null|  56|      null|  null|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default=> any\n",
    "# all 일 경우 모든 행이  null일경우 삭제\n",
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4306bb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|   A| 20|         2| 30000|\n",
      "|   B| 32|         1| 20000|\n",
      "|   C| 25|         3| 10000|\n",
      "|   D| 40|         5| 32000|\n",
      "|   E| 30|         1| 14000|\n",
      "|   F| 14|         3| 30000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46dd5186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|   A|  20|         2| 30000|\n",
      "|   B|  32|         1| 20000|\n",
      "|   C|  25|         3| 10000|\n",
      "|   D|  40|         5| 32000|\n",
      "|   E|  30|         1| 14000|\n",
      "|   F|  14|         3| 30000|\n",
      "|   G|null|      null| 50000|\n",
      "|null|  24|        10| 38000|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# threshold\n",
    "# 각 행에서 not null 의 개수가 thresh값보다 작을 경우 삭제 \n",
    "df_pyspark.na.drop(how='any',thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b020785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|   A| 20|         2| 30000|\n",
      "|   B| 32|         1| 20000|\n",
      "|   C| 25|         3| 10000|\n",
      "|   D| 40|         5| 32000|\n",
      "|   E| 30|         1| 14000|\n",
      "|   F| 14|         3| 30000|\n",
      "|null| 24|        10| 38000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any',thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ab1b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|   A| 20|         2| 30000|\n",
      "|   B| 32|         1| 20000|\n",
      "|   C| 25|         3| 10000|\n",
      "|   D| 40|         5| 32000|\n",
      "|   E| 30|         1| 14000|\n",
      "|   F| 14|         3| 30000|\n",
      "|null| 24|        10| 38000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subset => 해당 열의 null 값만 보겠다\n",
    "df_pyspark.na.drop(how='any',subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67db1cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|   A|  20|         2| 30000|\n",
      "|   B|  32|         1| 20000|\n",
      "|   C|  25|         3| 10000|\n",
      "|   D|  40|         5| 32000|\n",
      "|   E|  30|         1| 14000|\n",
      "|   F|  14|         3| 30000|\n",
      "|   G|null|      null| 50000|\n",
      "|9999|  24|        10| 38000|\n",
      "|9999|  56|      null|  null|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측값 채우기\n",
    "df_pyspark.na.fill('9999','Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52152973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|   A|  20|         2| 30000|\n",
      "|   B|  32|         1| 20000|\n",
      "|   C|  25|         3| 10000|\n",
      "|   D|  40|         5| 32000|\n",
      "|   E|  30|         1| 14000|\n",
      "|   F|  14|         3| 30000|\n",
      "|   G|9999|      9999| 50000|\n",
      "|null|  24|        10| 38000|\n",
      "|null|  56|      9999|  null|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측값 채우기\n",
    "df_pyspark.na.fill(9999,['Experience','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e10630e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|   A|  20|         2| 30000|\n",
      "|   B|  32|         1| 20000|\n",
      "|   C|  25|         3| 10000|\n",
      "|   D|  40|         5| 32000|\n",
      "|   E|  30|         1| 14000|\n",
      "|   F|  14|         3| 30000|\n",
      "|   G|null|      null| 50000|\n",
      "|null|  24|        10| 38000|\n",
      "|null|  56|      null|  null|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "706b44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a9c7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#선언한 열의 결측 값을 각 열의 평균으로 대체하는 코드\n",
    "imputer = Imputer(inputCols=['age','Experience','Salary'],\n",
    "                 outputCols=['{}_imputed'.format(c) for c in ['age','Experience','Salary']]\n",
    "                 ).setStrategy('mean') #median 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0516892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------------+------------------+-----------------+\n",
      "|summary|Name|               age|        Experience|           Salary|\n",
      "+-------+----+------------------+------------------+-----------------+\n",
      "|  count|   7|                 8|                 7|                8|\n",
      "|   mean|null|            30.125|3.5714285714285716|          28000.0|\n",
      "| stddev|null|13.076014027873436| 3.154739442867026|13049.35685333627|\n",
      "|    min|   A|                14|                 1|            10000|\n",
      "|    max|   G|                56|                10|            50000|\n",
      "+-------+----+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2df5d7af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+-----------+------------------+--------------+\n",
      "|Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+----+----+----------+------+-----------+------------------+--------------+\n",
      "|   A|  20|         2| 30000|         20|                 2|         30000|\n",
      "|   B|  32|         1| 20000|         32|                 1|         20000|\n",
      "|   C|  25|         3| 10000|         25|                 3|         10000|\n",
      "|   D|  40|         5| 32000|         40|                 5|         32000|\n",
      "|   E|  30|         1| 14000|         30|                 1|         14000|\n",
      "|   F|  14|         3| 30000|         14|                 3|         30000|\n",
      "|   G|null|      null| 50000|         30|                 3|         50000|\n",
      "|null|  24|        10| 38000|         24|                10|         38000|\n",
      "|null|  56|      null|  null|         56|                 3|         28000|\n",
      "+----+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#추가 열 생성 및 결측값 처리\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
